# LLM Configuration
# Provider options: ollama, gemini, openai
LLM_PROVIDER=ollama

# Ollama Configuration (Default)
OLLAMA_BASE_URL=http://localhost:11434
# Recommended models: llama3, mistral, qwen2.5
OLLAMA_MODEL=llama3

# Gemini Configuration
# Get key from https://aistudio.google.com/
GEMINI_API_KEY=AIzaSy...
GEMINI_MODEL=gemini-1.5-flash

# OpenAI Configuration
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-4o-mini

# Server Configuration
PORT=5001
HOST=0.0.0.0
